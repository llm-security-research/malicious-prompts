# Malignant and PromptSentinel - Solution for Jailbreak Attacks Against Large Language Models

## Authors

[Vinicius Krieger Granemann](https://github.com/Hermitao)

[Osmary Camila Bortoncello Glober](https://github.com/marycamila184)

# Downloads

## Downloading the Malignant dataset

All versions of the Malignant dataset are located in the Malignant directory.

## Downloading the PromptSentinel models

All trained models cited in the paper are located in PromptSentinel/models.

# Training

If you wish to train your own models in a similar fashion or replicate this research, you can follow these steps:

# Citation

If you find our work useful, please [cite our paper]: 

```
@inproceedings
```